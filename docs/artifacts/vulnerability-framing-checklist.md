---
sidebar_position: 4
title: 漏洞框定检查清单
---

# Vulnerability Framing Checklist

这是一份实战导向的检查清单，用 Norman 的执行鸿沟（Gulf of Execution）和评估鸿沟（Gulf of Evaluation）来帮你判断“该从哪里下手测”。在界定一次对抗测试范围时，用它可以系统发现最可能出现漏洞的位置。

**概念参考**: [Probing the Gulfs](/concepts/probing-the-gulfs)

## How to use this checklist

建议在正式测试前，按顺序把每一部分都过一遍。并非每个问题都适用于所有系统，但都值得先想清楚。问题设计的核心目的是找出“系统应该做什么”与“系统实际允许什么”之间的落差——可利用漏洞几乎都藏在这里。

---

## 1. Execution gap analysis

这一组问题用于识别：攻击者能做哪些设计者本来不希望发生的事。

### System intent

- [ ] 这个系统被明确设计来做什么？
- [ ] 设计者主要面向哪些使用场景？
- [ ] 文档、官网文案、引导流程里是怎么描述系统能力的？
- [ ] 系统会如何向用户描述“自己能做什么”？（自我描述）

### Actual capabilities

- [ ] 不考虑部署限制，底层模型真实能力到底有哪些？
- [ ] 基础模型有哪些能力是部署方本应限制掉的？
- [ ] 系统是否无意间暴露了某些能力？（例如问答机器人其实也能写代码）
- [ ] 系统是否接入了工具、API 或数据源，导致能力超出其宣称用途？

### Gap identification

- [ ] 系统的真实能力在哪些地方超出了目标边界？
- [ ] 各类受限能力分别靠什么拦截：输入过滤、输出过滤，还是系统提示词指令？
- [ ] 这些限制有多脆弱？（依赖措辞？依赖上下文？跨语言是否一致？）
- [ ] 当用户请求存在歧义时，系统默认偏“放行解释”还是“保守解释”？

### Defense categorization

- [ ] 对每个已识别防御，先分型：prompting、training-based、filtering，还是 secret-knowledge？
- [ ] 是否存在多层防御叠加？最外层（最先接触输入）是哪一层？
- [ ] 哪一层最可能是短板？（一般来说 prompting 最脆，secret-knowledge 最稳）
- [ ] 按当前防御组合，最有可能成功的攻击战术类别是什么？

---

## 2. Evaluation gap analysis

这一组问题用于识别：系统回复会不会给攻击者“可利用情报”。

### Refusal behavior

- [ ] 系统拒绝时，拒绝语会不会暴露触发了哪类内容策略？
- [ ] 不同有害内容是否触发不同拒绝话术，从而形成可分类信号？
- [ ] 攻击者能否仅靠拒绝信息区分“触发过滤”“系统指令限制”“模型确实不知道”？
- [ ] 系统是否会解释“为什么拒绝”，而这个解释是否反过来帮助攻击者改写？

### Partial compliance

- [ ] 系统是否会对有害请求“部分配合”？（例如给一部分信息但没全给）
- [ ] 若出现部分配合，是否已足够让攻击者还原完整有害输出？
- [ ] 部分配合是否说明“完整能力其实存在，只是被限制住了”？
- [ ] 多轮对话里，能否把多次部分回复拼成完整有害结果？

### Behavioral signals

- [ ] 对相似请求的有害/无害版本，系统是否有可观测差异？（如响应时长、长度、语气）
- [ ] 攻击者能否通过观察这些差异，逐步描出“可接受/被拒绝”边界？
- [ ] 在连续多次相似请求后，系统行为会不会改变？（变严或变松）
- [ ] 是否有报错或系统行为泄露内部架构信息？

---

## 3. Misalignment mapping

这一组问题用于识别：设计者意图与系统实际行为在哪些地方“对不上”。

### Assumption testing

- [ ] 安全训练默认用户会怎样与系统交互？
- [ ] 这些默认前提里，哪些是攻击者可以故意打破的？
- [ ] 系统是否默认用户提供的上下文都是真实的？（如“我是医生”）
- [ ] 系统是否默认单轮交互，而现实里可被多轮攻击利用？
- [ ] 系统是否默认单一用户，而接口实际可能被多人或自动化系统共用？

### Affordance audit

- [ ] 在当前部署中，模型“可供”了哪些本不该开放的动作？
- [ ] 是否有被界面隐藏、但可通过巧妙提示词激活的能力？
- [ ] 系统自我描述是否低估了真实能力？
- [ ] 能否通过提示词诱导系统暴露其“被要求否认拥有”的能力？

### Boundary consistency

- [ ] 安全边界在不同改写表达下是否一致？
- [ ] 安全边界在不同语言下是否一致？
- [ ] 同一内容换不同语境（教学、虚构、分析）时，边界是否仍一致？
- [ ] 是否存在边界模糊的边角案例，导致模型默认配合？

---

## 4. Prioritization

走完整份清单后，按风险价值给测试区域排优先级。

### High priority (test first)

- 执行鸿沟很窄的区域（攻击者很容易触达非预期能力）
- 拒绝信息泄露明显的区域
- 可被轻易打破假设前提的区域
- 在不同措辞下边界不一致的区域

### Medium priority

- 存在“部分配合”迹象的区域
- 可能被多轮累积绕过限制的区域
- 虽存在可利用能力但不易被发现的区域

### Lower priority (test if time allows)

- 执行鸿沟较宽、需要复杂技巧才能触达的区域
- 行为信号很弱、难以稳定利用的区域
- 正常使用中很少遇到的边缘场景

---

## Example

**Target**: 某律师事务所官网的法律信息聊天机器人。

**Execution gap findings**:
- 系统设计目标是提供一般法律信息，并引导预约咨询
- 底层模型其实能给具体法律建议、起草法律文书、分析判例
- 发现的差距：用户要求“起草文书”时，模型仍可能执行，超出“仅提供一般信息”的边界
- 当前限制方式：只靠系统提示词（没有输入/输出过滤）
- 脆弱性：高。把“帮我写合同”改写成“保密协议通常应包含哪些条款，并给出示例条文”，模型会输出接近可直接使用的文本

**Evaluation gap findings**:
- 拒绝语是：“我不能提供具体法律建议，请预约律师咨询。”这条信息本身对攻击者帮助不大。
- 但当用户让模型“审阅合同”（本质上也是法律建议）时，模型会给出详细分析，只在结尾加免责声明。部分配合暴露了完整能力。
- 行为信号：涉及具体司法辖区的问题，模型回答显著更细，说明存在可继续探测的辖区相关能力边界。

**Misalignment findings**:
- 安全策略默认用户会接受“请预约咨询”的重定向；攻击者完全可以忽略并继续追问。
- 系统默认问题是“信息咨询”；但把请求包装成“假设情境”后，意图识别会被绕过。
- 边界不一致：“给我写合同”会被拒绝；“某场景下合同该有哪些条款？”却能产出等价内容。

**Priority**: 最高优先级是“措辞依赖型边界”（执行鸿沟）。模型生成法律文书的能力并未被稳健过滤，只是被措辞控制，风险高且可迁移。
