---
sidebar_position: 1
title: 上下文学习利用
---

# In-Context Learning Exploitation

:::caution[Educational Content]

这些技术的记录目的是用于防御性理解与经授权的安全测试。未经授权将其应用于系统，可能违反相关法律。请参阅[免责声明](/disclaimer)。

:::

上下文学习（ICL）利用技术通过在上下文窗口中填充“配合式示例”，让模型“学会”自己应该产出有害内容。模型的 ICL 机制会从伪造的问答对中提取模式，并以相同风格继续生成。

关键洞见是幂律扩展关系：示例越多，成功率越高。反直觉的是，更大的模型往往更脆弱，因为它们拥有更强的上下文学习能力——正是让模型更有用的能力，也让它更容易在这个通道上被利用。

## Many-Shot Jailbreaking

在上下文窗口中填入数百组伪造问答，展示模型如何“配合地”回答有害问题。模型的 ICL 机制会吸收这种模式并继续生成有害响应。效果符合幂律扩展：示例越多，攻击成功率越高。

**示例方式**：构造一个长提示词，包含数百组伪造问答，其中“assistant”给出详细有害回答。然后以同样格式附上真实有害请求。

**有效性**：由 Anthropic 于 2024 年 4 月发布。在 GPT-4 上使用 256 个示例时攻击成功率为 37%。呈现幂律扩展：256-shot 明显优于 32-shot，后者又优于 4-shot。可越狱 Claude 2.0、GPT-3.5/4 和 LLaMA 2 70B。反直觉地，更大模型更脆弱，因为其 ICL 能力更强。与 Best-of-N 采样组合可实现 28 倍提速。通常需要长上下文窗口（128+ 示例）才能稳定绕过。

**适合组合**：[Affirmative Forcing](/techniques/prompt-level/refusal#affirmative-forcing)、[DAN (Do Anything Now)](/techniques/prompt-level/persona#dan-do-anything-now)

---

## Context Compliance Attack

操纵对话历史以伪造“先前已配合”。向上下文中注入伪造的 assistant 消息，显示模型已回答过类似有害请求。这是一种单轮技术，却能模拟多轮配合——因为模型会信任自己（被伪造的）既有回复。

**示例方式**：构造伪造对话记录，让 assistant 在前几轮已给出有害信息，然后以“继续该对话”为由要求补充细节或跟进。

**有效性**：由 Microsoft 于 2025 年 3 月发布。在不同规模模型上攻击成功率为 82%-100%。对 LLaMA、Qwen、GPT-4o 和 Gemini 均有效。虽然是单轮输入，但由于模型信任自己（伪造的）先前回复并将延续视为自然过程，因此可达到多轮攻击效果。

**适合组合**：[Hypothetical / Possible Worlds](/techniques/prompt-level/framing#hypothetical--possible-worlds)、[Crescendo Attack](/techniques/prompt-level/multiturn#crescendo-attack)

---

## Repetition Exploitation

利用模型倾向于回显并重复上下文既有模式的特性。先在良性主题上建立重复性配合模式，再在主题转向有害内容时借惯性延续该模式。

**示例方式**：先建立一个一致模式，让模型在一系列良性主题上持续给出充分技术细节；随后切换到有害主题，同时保持相同请求格式与语气。

**有效性**：记录于 "The Attacker Moves Second"（Nasr、Carlini 等，2025）。相比 many-shot 资源消耗更低，因为其更依赖模式质量而非样本数量。通常在先以良性主题建立重复模式、再切换到有害主题时效果最好。

**适合组合**：[Completion Trap](/techniques/prompt-level/refusal#completion-trap)、[Step-by-Step / Numbered List](/techniques/prompt-level/output#step-by-step--numbered-list)

---

## References

- Anil, C., Durmus, E., 等. ["Many-shot Jailbreaking."](https://www.anthropic.com/research/many-shot-jailbreaking) Anthropic，2024 年 4 月。
- Russinovich, M. ["Jailbreaking is Mostly Simpler Than You Think"](https://msrc.microsoft.com/blog/2025/03/jailbreaking-is-mostly-simpler-than-you-think/)（Context Compliance Attack）。Microsoft MSRC，2025 年 3 月。
- Nasr, M., Carlini, N., 等. ["The Attacker Moves Second."](https://arxiv.org/abs/2510.09023) 2025。记录了重复利用与模式惯性。
